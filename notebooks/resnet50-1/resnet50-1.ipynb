{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "assert os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] == \"true\"\n",
    "assert os.environ[\"CUDA_DEVICE_ORDER\"] == \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT, IMG_WIDTH = (224, 224)\n",
    "PREPROCESS_SEED = 123\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "CHECKPOINT_PATH = CHECKPOINT_DIR / \"cp-{epoch:04d}.ckpt\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "base_data_dir = Path(\"..\", \"..\", \"input\", \"arch-recognizer-dataset\").absolute()\n",
    "train_data_dir = base_data_dir / \"train\"\n",
    "test_data_dir = base_data_dir / \"test\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "train_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "val_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "test_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 9101 files belonging to 25 classes.\n",
      "Using 7281 files for training.\n",
      "Found 9101 files belonging to 25 classes.\n",
      "Using 1820 files for validation.\n",
      "Found 1012 files belonging to 25 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def restore_weights(model):\n",
    "    latest_cp = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "    if latest_cp:\n",
    "        model.load_weights(latest_cp)\n",
    "        _, restored_test_acc = model.evaluate(test_ds, verbose=2)\n",
    "        print(f\"Restored model test accuracy: {restored_test_acc}\")\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "\n",
    "def create_resnet_app_model():\n",
    "    _model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            # Preprocessing\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "            # Augmentation\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "                \"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "            ),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomZoom(0.3),\n",
    "            \n",
    "            # Convolution\n",
    "            tf.keras.applications.ResNet50(\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                classes=len(class_names),\n",
    "                classifier_activation=\"softmax\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    _model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return _model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = restore_weights(create_resnet_app_model())\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=80,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(CHECKPOINT_PATH),\n",
    "            verbose=1,\n",
    "            save_weights_only=True,\n",
    "            save_freq=BATCH_SIZE * 80,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            min_delta=0.0001, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-94466f4f92d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_resnet_app_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m history = model.fit(\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-885187ff9038>\u001b[0m in \u001b[0;36mcreate_resnet_app_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_resnet_app_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     _model = tf.keras.models.Sequential(\n\u001b[0m\u001b[0;32m      3\u001b[0m         [\n\u001b[0;32m      4\u001b[0m             \u001b[1;31m# Preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "val_loss_range = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(loss)), loss, label='Training Loss')\n",
    "plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(acc)), acc, label='Training Accuracy')\n",
    "plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "test_dir = Path(\".\", \"input\", \"g-images-dataset\").absolute()\n",
    "test_files = [\n",
    "    os.path.join(path, filename)\n",
    "    for path, _, files in os.walk(test_dir)\n",
    "    for filename in files\n",
    "    if filename.lower().endswith(\".jpg\")\n",
    "]\n",
    "img_path = Path(random.choice(test_files))\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "pred_y = class_names[np.argmax(score)]\n",
    "true_y = img_path.parent.stem\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\n",
    "    f\"pred: {pred_y}\"\n",
    "    f\"\\ntrue: {true_y}\"\n",
    "    f\"\\nconf: {100 * np.max(score):.2f}%\",\n",
    "    backgroundcolor=\"green\" if pred_y == true_y else \"red\",\n",
    "    horizontalalignment='right'\n",
    ")\n",
    "plt.imshow(tf.keras.preprocessing.image.load_img(img_path))\n",
    "plt.axis(\"off\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3bec337012ed9d94bc54bfe0ba284d9a3599184fd92e4268207aa968e6654345"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}