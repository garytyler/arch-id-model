version: "3"
services:
  training:
    container_name: training
    build:
      context: .
      target: train-stage
      args:
        - "USERNAME=${USER}"
    ports:
      - 6006:6006
    runtime: nvidia
    environment:
      - "TF_FORCE_GPU_ALLOW_GROWTH=true"
      - "CUDA_DEVICE_ORDER=PCI_BUS_ID"
      - "NVIDIA_VISIBLE_DEVICES=${GPUS}"
      - "NVIDIA_DRIVER_CAPABILITIES=compute,utility"
    working_dir: /workspace
    volumes:
      - .:/workspace:rw
    command: bash -c "ulimit -n 4092 && cd notebooks/${NB} && jupyter nbconvert --to notebook --execute ${NB}.ipynb"

  # orchestrator:
  #   build:
  #     context: .
  #     target: dev-stage
  #     args:
  #       - USERNAME=${USER}
  #   ports:
  #     - 6006:6006
  #   runtime: nvidia
  #   command: /bin/sh -c "while sleep 1000; do :; done"
  #   volumes:
  #     - workspace:/workspace
  #     - .:/workspace:rw
  #     - /var/run/docker.sock:/var/run/docker.sock

  # build:
  #   context: .
  #   dockerfile: ./Dockerfile.orchestrate
  #   args:
  #     - "USERNAME=${USER}"
  # ports:
  #   - 6006:6006
  # runtime: nvidia
  # environment:
  #   - "TF_FORCE_GPU_ALLOW_GROWTH=true"
  #   - "CUDA_DEVICE_ORDER=PCI_BUS_ID"
  #   - "NVIDIA_VISIBLE_DEVICES=${GPUS}"
  #   - "NVIDIA_DRIVER_CAPABILITIES=compute,utility"
  # working_dir: /workspace
  # volumes:
  #   - .:/workspace:rw
