{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import os\n",
    "\n",
    "assert os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] == \"true\"\n",
    "assert os.environ[\"CUDA_DEVICE_ORDER\"] == \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] == \"0,1,2\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "PREPROCESS_SEED = 123"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "base_data_dir = Path(\".\", \"input\", \"arch-recognizer-dataset\").absolute()\n",
    "train_data_dir = base_data_dir / \"train\"\n",
    "test_data_dir = base_data_dir / \"test\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "class_names = train_ds.class_names\n",
    "train_ds = (\n",
    "    train_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_ds = (\n",
    "    val_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_ds = (\n",
    "    val_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 9101 files belonging to 25 classes.\n",
      "Using 7281 files for training.\n",
      "Found 9101 files belonging to 25 classes.\n",
      "Using 1820 files for validation.\n",
      "Found 1012 files belonging to 25 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "augmentation_layer = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "            \"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "        ),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.3),\n",
    "    ]\n",
    ")\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        augmentation_layer,\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "            1.0 / 255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "        ),\n",
    "        # tf_hub.KerasLayer(\n",
    "        #     \"https://tfhub.dev/google/imagenet/inception_v1/classification/5\",\n",
    "        #     trainable=False,\n",
    "        # ),\n",
    "        # tf_hub.KerasLayer(\n",
    "        #     \"https://tfhub.dev/sayakpaul/bit_r152x2_224_feature_extraction/1\",\n",
    "        #     trainable=False,\n",
    "        # ),\n",
    "        tf_hub.KerasLayer(\n",
    "            \"https://tfhub.dev/sayakpaul/distill_bit_r50x1_224_feature_extraction/1\",\n",
    "            trainable=False,\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(len(class_names)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# model = tf.keras.models.Sequential(\n",
    "#     [\n",
    "#         tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "#             1.0 / 255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "#         ),\n",
    "#         tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(),\n",
    "#         tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(),\n",
    "#         tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(len(class_names)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_1 (Rescaling)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)   (None, 2048)              23500352  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 23,765,849\n",
      "Trainable params: 265,497\n",
      "Non-trainable params: 23,500,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "epochs = 50\n",
    "with tf.device(\"/device:GPU:1\"):\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                min_delta=0.0001, patience=10, restore_best_weights=True\n",
    "            )\n",
    "        ],\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "57/57 [==============================] - 99s 1s/step - loss: 2.2446 - accuracy: 0.3780 - val_loss: 1.4406 - val_accuracy: 0.5670\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 1.3944 - accuracy: 0.5800 - val_loss: 1.2127 - val_accuracy: 0.6236\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 1.1954 - accuracy: 0.6304 - val_loss: 1.1540 - val_accuracy: 0.6319\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 1.1012 - accuracy: 0.6576 - val_loss: 1.0992 - val_accuracy: 0.6407\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 1.0301 - accuracy: 0.6815 - val_loss: 1.0413 - val_accuracy: 0.6604\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.9626 - accuracy: 0.7017 - val_loss: 1.0266 - val_accuracy: 0.6676\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.9341 - accuracy: 0.7124 - val_loss: 1.0327 - val_accuracy: 0.6698\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.8836 - accuracy: 0.7228 - val_loss: 1.0099 - val_accuracy: 0.6846\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.8568 - accuracy: 0.7316 - val_loss: 0.9712 - val_accuracy: 0.6846\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.8169 - accuracy: 0.7466 - val_loss: 0.9677 - val_accuracy: 0.6923\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.7907 - accuracy: 0.7509 - val_loss: 0.9744 - val_accuracy: 0.6962\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.7721 - accuracy: 0.7507 - val_loss: 0.9619 - val_accuracy: 0.6989\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.7461 - accuracy: 0.7643 - val_loss: 0.9643 - val_accuracy: 0.6995\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.7335 - accuracy: 0.7679 - val_loss: 0.9777 - val_accuracy: 0.6912\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.7071 - accuracy: 0.7765 - val_loss: 0.9587 - val_accuracy: 0.6956\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.6924 - accuracy: 0.7820 - val_loss: 0.9719 - val_accuracy: 0.6929\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.6578 - accuracy: 0.7930 - val_loss: 0.9595 - val_accuracy: 0.6984\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.6455 - accuracy: 0.7985 - val_loss: 0.9615 - val_accuracy: 0.7005\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.6361 - accuracy: 0.8010 - val_loss: 0.9535 - val_accuracy: 0.7071\n",
      "Epoch 20/50\n",
      "12/57 [=====>........................] - ETA: 44s - loss: 0.5939 - accuracy: 0.8249"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "val_loss_range = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(loss)), loss, label='Training Loss')\n",
    "plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(acc)), acc, label='Training Accuracy')\n",
    "plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "# sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "import random\n",
    "\n",
    "test_dir = Path(\".\", \"input\", \"g-images-dataset\").absolute()\n",
    "test_files = [\n",
    "    os.path.join(path, filename)\n",
    "    for path, dirs, files in os.walk(test_dir)\n",
    "    for filename in files\n",
    "    if filename.lower().endswith(\".jpg\")\n",
    "]\n",
    "img_path = Path(random.choice(test_files))\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "pred_y = class_names[np.argmax(score)]\n",
    "true_y = img_path.parent.stem\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\n",
    "    f\"pred: {pred_y}\"\n",
    "    f\"\\ntrue: {true_y}\"\n",
    "    f\"\\nconf: {100 * np.max(score):.2f}%\",\n",
    "    backgroundcolor=\"green\" if pred_y == true_y else \"red\",\n",
    "    horizontalalignment='right'\n",
    ")\n",
    "plt.imshow(tf.keras.preprocessing.image.load_img(img_path))\n",
    "plt.axis(\"off\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3bec337012ed9d94bc54bfe0ba284d9a3599184fd92e4268207aa968e6654345"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}