{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "\n",
    "assert os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] == \"true\"\n",
    "assert os.environ[\"CUDA_DEVICE_ORDER\"] == \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] == \"1\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "GPU_BUS_ID = 1\n",
    "NOTEBOOK_NAME = \"distill_bit_r50x1_224_feature_extraction-plain\"\n",
    "BATCH_SIZE = 128\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "PREPROCESS_SEED = 123"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "base_data_dir = Path(\"..\", \"input\", \"arch-recognizer-dataset\").absolute()\n",
    "train_data_dir = base_data_dir / \"train\"\n",
    "test_data_dir = base_data_dir / \"test\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "class_names = train_ds.class_names\n",
    "train_ds = (\n",
    "    train_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_ds = (\n",
    "    val_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_ds = (\n",
    "    val_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 9101 files belonging to 25 classes.\n",
      "Using 7281 files for training.\n",
      "Found 9101 files belonging to 25 classes.\n",
      "Using 1820 files for validation.\n",
      "Found 1012 files belonging to 25 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def create_model():\n",
    "    _model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "                \"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "            ),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomZoom(0.3),\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "                1.0 / 255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "            ),\n",
    "            tf_hub.KerasLayer(\n",
    "                \"https://tfhub.dev/sayakpaul/distill_bit_r50x1_224_feature_extraction/1\",\n",
    "                trainable=False,\n",
    "            ),\n",
    "            tf.keras.layers.Dense(len(class_names)),\n",
    "        ]\n",
    "    )\n",
    "    _model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return _model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create a callback that saves the model's weights periodically\n",
    "cp_dir = Path(NOTEBOOK_NAME)\n",
    "cp_path = cp_dir / \"cp-{epoch:04d}.ckpt\"\n",
    "model = create_model()\n",
    "\n",
    "# Load checkpoint if found\n",
    "latest_cp = tf.train.latest_checkpoint(cp_dir)\n",
    "if latest_cp:\n",
    "    model.load_weights(latest_cp)\n",
    "    restored_test_loss, restored_test_acc = model.evaluate(test_ds, verbose=2)\n",
    "    print(f\"Restored model test accuracy: {restored_test_acc}\")\n",
    "    \n",
    "# Train\n",
    "# with tf.device(f\"/device:GPU:{GPU_BUS_ID}\"):\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=80,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(cp_path),\n",
    "            verbose=1,\n",
    "            save_weights_only=True,\n",
    "            save_freq=BATCH_SIZE,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            min_delta=0.0001, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    ],\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15/15 - 23s - loss: 1.5922 - accuracy: 0.5819\n",
      "Restored model test accuracy: 0.5818681120872498\n",
      "Epoch 1/80\n",
      "57/57 [==============================] - 90s 1s/step - loss: 1.6139 - accuracy: 0.5840 - val_loss: 1.4216 - val_accuracy: 0.5852\n",
      "Epoch 2/80\n",
      "57/57 [==============================] - 66s 1s/step - loss: 1.4565 - accuracy: 0.6101 - val_loss: 1.3192 - val_accuracy: 0.6093\n",
      "Epoch 3/80\n",
      "14/57 [======>.......................] - ETA: 39s - loss: 1.3588 - accuracy: 0.6306\n",
      "Epoch 00003: saving model to distill_bit_r50x1_224_feature_extraction-plain\\cp-0003.ckpt\n",
      "57/57 [==============================] - 68s 1s/step - loss: 1.3555 - accuracy: 0.6281 - val_loss: 1.2518 - val_accuracy: 0.6242\n",
      "Epoch 4/80\n",
      "14/57 [======>.......................] - ETA: 40s - loss: 1.3045 - accuracy: 0.6365"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "val_loss_range = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(loss)), loss, label='Training Loss')\n",
    "plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(acc)), acc, label='Training Accuracy')\n",
    "plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "# sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "import random\n",
    "\n",
    "test_dir = Path(\".\", \"input\", \"g-images-dataset\").absolute()\n",
    "test_files = [\n",
    "    os.path.join(path, filename)\n",
    "    for path, _, files in os.walk(test_dir)\n",
    "    for filename in files\n",
    "    if filename.lower().endswith(\".jpg\")\n",
    "]\n",
    "img_path = Path(random.choice(test_files))\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "pred_y = class_names[np.argmax(score)]\n",
    "true_y = img_path.parent.stem\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\n",
    "    f\"pred: {pred_y}\"\n",
    "    f\"\\ntrue: {true_y}\"\n",
    "    f\"\\nconf: {100 * np.max(score):.2f}%\",\n",
    "    backgroundcolor=\"green\" if pred_y == true_y else \"red\",\n",
    "    horizontalalignment='right'\n",
    ")\n",
    "plt.imshow(tf.keras.preprocessing.image.load_img(img_path))\n",
    "plt.axis(\"off\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3bec337012ed9d94bc54bfe0ba284d9a3599184fd92e4268207aa968e6654345"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}