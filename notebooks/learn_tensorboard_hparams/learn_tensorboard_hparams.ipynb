{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import io"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT, IMG_WIDTH = (224, 224)\n",
    "PREPROCESS_SEED = 123\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "CHECKPOINT_PATH = CHECKPOINT_DIR / \"cp-{epoch:04d}.ckpt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "source": [
    "base_data_dir = Path(\"..\", \"..\", \"input\", \"arch-recognizer-dataset\").absolute()\n",
    "val_data_dir = base_data_dir / \"val\"\n",
    "test_data_dir = base_data_dir / \"test\"\n",
    "train_data_dir = base_data_dir / \"train\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "source": [
    "# Import data\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "train_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "val_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "test_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "\n",
    "train_ds.map(\n",
    "    lambda i, _: tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(i)\n",
    ")\n",
    "val_ds.map(\n",
    "    lambda i, _: tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(i)\n",
    ")\n",
    "test_ds.map(\n",
    "    lambda i, _: tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(i)\n",
    ")\n",
    "\n",
    "train_ds = (\n",
    "    train_ds.shuffle(5000, reshuffle_each_iteration=True)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_ds = (\n",
    "    val_ds.shuffle(5000, reshuffle_each_iteration=True)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2021 files belonging to 25 classes.\n",
      "Found 1012 files belonging to 25 classes.\n",
      "Found 7080 files belonging to 25 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "source": [
    "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# (x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "source": [
    "# Configure Hyperparameters\n",
    "\n",
    "HP_POOLING = hp.HParam(\n",
    "    \"pooling\",\n",
    "    hp.Discrete(\n",
    "        [\n",
    "            # None,\n",
    "            \"max\",\n",
    "            \"avg\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "HP_OPTIMIZER = hp.HParam(\n",
    "    \"optimizer\",\n",
    "    hp.Discrete(\n",
    "        [\n",
    "            # tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            # tf.keras.optimizers.SGD(),\n",
    "            \"adam\",\n",
    "            \"sgd\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "METRIC_ACCURACY = \"test_accuracy\"\n",
    "\n",
    "with tf.summary.create_file_writer(f\"logs/hparam_tuning\").as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[\n",
    "            # HP_WEIGHTS,\n",
    "            HP_POOLING,\n",
    "            HP_OPTIMIZER,\n",
    "        ],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name=\"Test Accuracy\")],\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "source": [
    "def restore_weights(model):\n",
    "    latest_cp = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "    if latest_cp:\n",
    "        model.load_weights(latest_cp)\n",
    "        _, restored_test_acc = model.evaluate(test_ds, verbose=2)\n",
    "        print(f\"Restored model test accuracy: {restored_test_acc}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_test_model(hparams, session_num):\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            # Preprocessing\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "            # Augmentation\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "                \"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "            ),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "            tf.keras.applications.ResNet50(\n",
    "                include_top=True,\n",
    "                # weights=hparams[HP_WEIGHTS][1],\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                # pooling=hparams[HP_POOLING][1],\n",
    "                # classes=len(class_names),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    restore_weights(model)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    log_dir = Path(\"logs\", f\"run-{session_num}\")\n",
    "\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=str(log_dir))\n",
    "\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(len(class_names), len(class_names)))\n",
    "        plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.0\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        plt.show()\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(str(log_dir / \"cm\"))\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        pred_labels, true_labels = [], []\n",
    "        for batch_images, batch_labels in test_ds:  # use dataset.unbatch() with repeat\n",
    "            true_labels.extend(batch_labels)\n",
    "            preds = model.predict(batch_images)\n",
    "            pred_labels.extend(np.argmax(preds, axis=-1))\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(true_labels, pred_labels)\n",
    "        cm = np.nan_to_num(cm)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "    # Define the per-epoch callback.\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1, profile_batch=0\n",
    "    )\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        min_delta=0.0001, patience=10, restore_best_weights=True\n",
    "    )\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(CHECKPOINT_DIR)\n",
    "        + f\"/run-{session_num}\"\n",
    "        + \"-epoch-{epoch:04d}.ckpt\",\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_freq=BATCH_SIZE * 100,\n",
    "    )\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,\n",
    "        callbacks=[tb_callback, cm_callback, es_callback, cp_callback],\n",
    "    )\n",
    "    _, accuracy = model.evaluate(test_ds)\n",
    "    return accuracy\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "source": [
    "def run(run_dir, hparams, session_num):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs --bind_all\n",
    "\n",
    "# Perform training runs\n",
    "session_num = 0\n",
    "for pooling in HP_POOLING.domain.values:\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        hparams = {\n",
    "            # HP_WEIGHTS: weights,\n",
    "            HP_POOLING: pooling,\n",
    "            HP_OPTIMIZER: optimizer,\n",
    "        }\n",
    "        run_name = f\"run-{session_num}\"\n",
    "        print(f\"--- Starting trial: {run_name}\")\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run(f\"logs/{run_name}\", hparams, session_num)\n",
    "        session_num += 1"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6efd0ae3a84fd5d9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6efd0ae3a84fd5d9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Starting trial: run-0\n",
      "{'pooling': 'avg', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-c81a6396a3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Starting trial: {run_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"logs/{run_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msession_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-450-78fa063a28e6>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_dir, hparams, session_num)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# record the values used in this trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC_ACCURACY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-449-1a33573ca768>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(hparams, session_num)\u001b[0m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m     cp_callback = tf.keras.callbacks.ModelCheckpoint(\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"run-{session_num}\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-epoch-{epoch:04d}.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}