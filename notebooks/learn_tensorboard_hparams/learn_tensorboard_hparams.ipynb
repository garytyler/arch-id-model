{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import io"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT, IMG_WIDTH = (224, 224)\n",
    "PREPROCESS_SEED = 123\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "CHECKPOINT_PATH = CHECKPOINT_DIR / \"cp-{epoch:04d}.ckpt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "source": [
    "base_data_dir = Path(\"..\", \"..\", \"input\", \"arch-recognizer-dataset\").absolute()\n",
    "val_data_dir = base_data_dir / \"val\"\n",
    "test_data_dir = base_data_dir / \"test\"\n",
    "train_data_dir = base_data_dir / \"train\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "source": [
    "# Import data\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    seed=PREPROCESS_SEED,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "train_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "val_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "test_ds.map(lambda i, _: tf.keras.applications.resnet.preprocess_input(i))\n",
    "\n",
    "train_ds.map(\n",
    "    lambda i, _: tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(i)\n",
    ")\n",
    "val_ds.map(\n",
    "    lambda i, _: tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(i)\n",
    ")\n",
    "test_ds.map(\n",
    "    lambda i, _: tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(i)\n",
    ")\n",
    "\n",
    "train_ds = (\n",
    "    train_ds.shuffle(5000, reshuffle_each_iteration=True)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_ds = (\n",
    "    val_ds.shuffle(5000, reshuffle_each_iteration=True)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2021 files belonging to 25 classes.\n",
      "Found 1012 files belonging to 25 classes.\n",
      "Found 7080 files belonging to 25 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "source": [
    "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# (x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "source": [
    "# Configure Hyperparameters\n",
    "\n",
    "HP_POOLING = hp.HParam(\n",
    "    \"pooling\",\n",
    "    hp.Discrete(\n",
    "        [\n",
    "            # None,\n",
    "            \"max\",\n",
    "            \"avg\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "HP_OPTIMIZER = hp.HParam(\n",
    "    \"optimizer\",\n",
    "    hp.Discrete(\n",
    "        [\n",
    "            # tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            # tf.keras.optimizers.SGD(),\n",
    "            \"adam\",\n",
    "            \"sgd\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "METRIC_ACCURACY = \"test_accuracy\"\n",
    "\n",
    "with tf.summary.create_file_writer(f\"logs/hparam_tuning\").as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[\n",
    "            # HP_WEIGHTS,\n",
    "            HP_POOLING,\n",
    "            HP_OPTIMIZER,\n",
    "        ],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name=\"Test Accuracy\")],\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "source": [
    "def restore_weights(model):\n",
    "    latest_cp = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "    if latest_cp:\n",
    "        model.load_weights(latest_cp)\n",
    "        _, restored_test_acc = model.evaluate(test_ds, verbose=2)\n",
    "        print(f\"Restored model test accuracy: {restored_test_acc}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_test_model(hparams, session_num):\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            # Preprocessing\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "            # Augmentation\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "                \"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "            ),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "            tf.keras.applications.ResNet50(\n",
    "                include_top=True,\n",
    "                # weights=hparams[HP_WEIGHTS][1],\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                # pooling=hparams[HP_POOLING][1],\n",
    "                # classes=len(class_names),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    restore_weights(model)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    log_dir = Path(\"logs\", f\"run-{session_num}\")\n",
    "\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=str(log_dir))\n",
    "\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(len(class_names), len(class_names)))\n",
    "        plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.0\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        plt.show()\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(str(log_dir / \"cm\"))\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        pred_labels, true_labels = [], []\n",
    "        for batch_images, batch_labels in test_ds:  # use dataset.unbatch() with repeat\n",
    "            true_labels.extend(batch_labels)\n",
    "            preds = model.predict(batch_images)\n",
    "            pred_labels.extend(np.argmax(preds, axis=-1))\n",
    "\n",
    "        # # Convert into tensors\n",
    "        # pred_labels_tensors = tf.concat([item for item in pred_labels], axis=0)\n",
    "        # true_labels_tensors = tf.concat([item for item in true_labels], axis=0)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(true_labels, pred_labels)\n",
    "        cm = np.nan_to_num(cm)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "    # Define the per-epoch callback.\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1, profile_batch=0\n",
    "    )\n",
    "\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    es_callback = (\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            min_delta=0.0001, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,  \n",
    "        callbacks=[tb_callback, cm_callback, es_callback],\n",
    "    )\n",
    "    _, accuracy = model.evaluate(test_ds)\n",
    "    return accuracy\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "source": [
    "def run(run_dir, hparams, session_num):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs --bind_all\n",
    "\n",
    "# Perform training runs\n",
    "session_num = 0\n",
    "for pooling in HP_POOLING.domain.values:\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        hparams = {\n",
    "            # HP_WEIGHTS: weights,\n",
    "            HP_POOLING: pooling,\n",
    "            HP_OPTIMIZER: optimizer,\n",
    "        }\n",
    "        run_name = f\"run-{session_num}\"\n",
    "        print(f\"--- Starting trial: {run_name}\")\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run(f\"logs/{run_name}\", hparams, session_num)\n",
    "        session_num += 1"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8184ea00b40ee17d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8184ea00b40ee17d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Starting trial: run-0\n",
      "{'pooling': 'avg', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "443/443 [==============================] - 134s 274ms/step - loss: 3.2539 - accuracy: 0.1066 - val_loss: 3.6879 - val_accuracy: 0.0782\n",
      "Epoch 2/100\n",
      "443/443 [==============================] - 112s 254ms/step - loss: 2.8851 - accuracy: 0.1486 - val_loss: 3.6581 - val_accuracy: 0.0891\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}